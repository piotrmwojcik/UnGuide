{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A notebook for testing stable diffusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "import sys, os\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    print('Top of sys.path:', sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import wandb\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from data_utils import  TargetReferenceDataset, collate_prompts\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import numpy as np\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from ldm.models.diffusion.ddimcopy import DDIMSampler\n",
    "from utils import get_models, print_trainable_parameters, set_seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_orig, sampler_orig, model, sampler = get_models(\n",
    "    \"../configs/stable-diffusion/v1-inference.yaml\", \"../models/sd-v1-4.ckpt\", \"cuda\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_and_save_sd_images(\n",
    "    model,\n",
    "    sampler,\n",
    "    prompt: str,\n",
    "    device: torch.device,\n",
    "    steps: int = 50,\n",
    "    eta: float = 0.0,\n",
    "    batch_size: int = 1,\n",
    "    out_dir: str = \"tmp\",\n",
    "    prefix: str = \"unl_\",\n",
    "    start_code: torch.Tensor = None,   # optional noise tensor [B,4,64,64] (for 512x512)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates images with CFG from a CompVis SD model + DDIMSampler and saves them.\n",
    "\n",
    "    - model: Stable Diffusion model (CompVis LDM style)\n",
    "    - sampler: DDIMSampler(model)\n",
    "    - prompt: text prompt\n",
    "    - device: torch.device(\"cuda\") or torch.device(\"cpu\")\n",
    "    - steps: DDIM steps\n",
    "    - eta: DDIM eta (0.0 => deterministic)\n",
    "    - batch_size: number of samples to generate\n",
    "    - out_dir: folder to save into\n",
    "    - prefix: file prefix, e.g., 'unl_'\n",
    "    - start_code: optional start noise of shape [B, 4, H/8, W/8]; if None, sampled internally.\n",
    "                  For 512×512 set shape to [B, 4, 64, 64].\n",
    "    \"\"\"\n",
    "    # derive latent shape from start_code or default to 512×512\n",
    "    if start_code is None:\n",
    "        start_code = torch.randn(batch_size, 4, 64, 64, device=device)  # 512x512\n",
    "\n",
    "    # freeze & eval for safety\n",
    "\n",
    "    with torch.no_grad(), torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "        cond   = model.get_learned_conditioning([prompt] * start_code.shape[0])\n",
    "        uncond = model.get_learned_conditioning([\"\"] * start_code.shape[0])\n",
    "\n",
    "        samples_latent, _ = sampler.sample(\n",
    "            S=steps,\n",
    "            conditioning={\"c_crossattn\": [cond]},\n",
    "            batch_size=start_code.shape[0],\n",
    "            shape=start_code.shape[1:],  # (4, H/8, W/8)\n",
    "            verbose=False,\n",
    "            unconditional_guidance_scale=7.5,                 # CFG scale; tweak if needed\n",
    "            unconditional_conditioning={\"c_crossattn\": [uncond]},\n",
    "            eta=eta,\n",
    "            x_T=start_code,\n",
    "        )\n",
    "\n",
    "        # decode latents to [0,1] images\n",
    "        imgs = model.decode_first_stage(samples_latent)       # [-1, 1]\n",
    "        imgs = (imgs.clamp(-1, 1) + 1) / 2.0                 # [0, 1]\n",
    "\n",
    "        # save\n",
    "        out_path = Path(out_dir)\n",
    "        out_path.mkdir(exist_ok=True)\n",
    "        for i, im in enumerate(imgs.cpu()):\n",
    "            im_u8 = (im.clamp(0, 1) * 255).round().to(torch.uint8)  # [3,H,W]\n",
    "            to_pil_image(im_u8).save(out_path / f\"{prefix}{i:04d}.png\")\n",
    "\n",
    "        print(f\"Saved {len(imgs)} image(s) to {out_path}/ with prefix '{prefix}'\")\n",
    "        return imgs  # [B,3,H,W] in [0,1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampler = DDIMSampler(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = generate_and_save_sd_images(\n",
    "    model=model,\n",
    "    sampler=sampler,\n",
    "    prompt=\"a photo of the bird\",\n",
    "    device=torch.device(\"cuda\"),\n",
    "    steps=50,\n",
    "    out_dir=\"tmp\",\n",
    "    prefix=\"orig_\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = img[0].detach().cpu()\n",
    "if x.dtype == torch.uint8:\n",
    "    arr = x.permute(1, 2, 0).numpy()      # HWC uint8 [0,255]\n",
    "else:\n",
    "    x = x.float()\n",
    "    arr = x.permute(1, 2, 0).numpy()      # HWC float [0,1]\n",
    "\n",
    "plt.imshow(arr)\n",
    "plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}